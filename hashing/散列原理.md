### 散列\(Hashing\)原理

1.散列是一种赖以高效组织数据并实现相关算法的重要思想

2.实例:字母对应手机拨号键的数字  
  e.g.MAGIC = 62442; BAIDU = 22438

1. Vector :call by rank  
   List   :call by posi  
   BST    :call by key  
   Hashing:call by value \(找到的对象本身:value, 数值;这就是散列\)

4.原理  
\(1\)桶\(bucket\):直接存放或间接指向一个词条

\(2\)桶数组\(bucket array\)/散列表\(hash table\):容量为M  
   N\(需要检索的词条数量\) &lt; M &lt;&lt; R \(总词条数量\)  
   空间 = O\(N+M\) = O\(N\) \(N和M同阶\)

\(3\)定址/杂凑/散列\(hashing\):  
   根据词条的key\(未必可比较\)  
   直接确定散列表入口

\(4\)散列函数:hash\(\) : key -&gt; &entry

![](/assets/hashing.png)

5.但是如何得到散列表\(hash table\)呢?  
\(1\)实例  
   -散列函数\(整数取模/mod\(\)\): hash\(key\) = key % M  
   -散列表长: M = 90,001  
   -实际存放记录数:N = 25,000  
   -空间利用率: = N/M ~= 25%, 也称作装填因子\(load factor\),简记作lambda

\(3\)以上方法可能出现散列冲突\(Hash Collision\):  
   两个映射码可能映射到同一个桶单元

\(4\)解决方法之一:  
   降低load factor\(lambda\),也就是提高散列表长M

\(5\)鸽巢原理:  
   从一个大的Region映射到相对小的Region,冲突无法彻底避免

\(6\)有效排解冲突是下面研究的重点

### 散列函数

1.无法杜绝的冲突  
\(1\)散列函数hash\(\):是映射,但不能一一映射\(单射\)  
\(2\)所以要精心设计散列表和散列函数,尽可能降低冲突的概率  
\(3\)并且需要制定可行的预案,当发生冲突时尽快排解

2.什么样的散列函数hash\(\)更好?  
\(1\)确定性\(determinism\):同一关键码总是被映射至同一地址  
\(2\)快速\(efficiency\):expect O\(1\)  
\(3\)满射\(surjection\):尽可能充分地覆盖整个散列空间  
\(4\)均匀\(uniformity\):关键码映射到散列表各位置的概率尽量接近,可有效避免聚集\(clustering\)现象

3.散列函数方法1:除余法  
\(1\)hash\(key\) = key % M  
\(2\)前面的例子中,为何选M = 90001? 而不是选2的k次方以高效计算\(用位与运算\)?

其实可以选M = 2^k? 而且计算余数方便: k%M = k&\(M-1\)  
但是结果却是最后k位相同的概率大, 违背了均匀分布的性质  
M为素数时, 覆盖最充分, 分布最均匀  
\(我的想法:素数是相对于我们常用的十进制来说的,假如用别的进制,我们定义的素数就没用了?\)

\(3\)以上方法破坏了均匀性:在整个关键码的取值空间中,存在某个特定的子集,该子集中的每一个元素都会统一的映射到散列表中的某一个特定单元,而不是均匀的分布于整个散列表中  
\(4\)取90001可稍有改进,但更好的方法是取M为_素数\(Prime number\)_  
\(5\)这样不仅数据对散列表的覆盖程度能够达到最充分,而且分布将达到最均匀

4.以蝉为师\(也就是使用素数做散列表长度\)

\(1\)我们处理的数据通常具有局部性, 可能带有一定的规律, 比如在循环中递增的序列等  
\(2\)选取素数,任何序列步长和该素数的最大公因子\(Greatest Common Divisor,G.C.D.\)都是1  
\(3\)并且任何步长都能遍历整个散列表空间\(具有均匀性\)  
\(4\)蝉的生命周期都是素数\(11,13,17等\),这样能尽量避免与其天敌的生命周期\(强盛期\)重合.  
\(5\)例子:  
按3的步长递增的数据, 然后用13做为散列表长

```
0   3   6   9   12  =>　0   3   6   9   12  
15  18  21  24  27　=>  2   5   8   11  1
```

5.M.A.D法\(改进除余法\)  
\(1\)除余法均匀性缺陷:  
   -不动点:无论表长M取值如何,总有hash\(0\)==0  
   -零阶均匀:\[0,R\)的关键码,平均分配至M个桶;但相邻关键码的散列地址也必相邻\(低阶均匀\)
   -一阶均匀:邻近关键码, 散列地址不邻近

\(2\)实现高阶均匀性:  
   MAD = multiply-add-divide  
   取M为素数,a&gt;0,b&gt;0,a%M!=0  
   hash\(key\) = \(a\*key+b\) % M

\(3\)以上的a和b:  
b可视作偏移量\(offset\)可消除不动点;  
a为步长,原本相邻的关键码,将变成间隔a,从而不再相邻.

\(4\)其他场合可能未必需要高阶均匀性:  
   -几何计算:尽可能使得临近的关键码,被映射到临近的位置\(locality sensitive hashing\)  
   -密码学:小空间映射到大空间\(而不是通常的大空间映射到小空间\)

6.平方取中  
\(1\)数字分析\(selecting digits\)  
抽取key中的某几位,构成地址\(比如,取十进制表示的奇数位\)\(但没有均匀性\)  
\(2\)平方取中\(mid-square\)  
取key^2的中间若干位,构成地址  
hash\(123\)= 512; //key^2 = 123^2 = 1 512 9  
hash\(1234567\) = 556; //1234567^2 = 15241 556 77489  
\(3\)平方取中的原理?  
为了使得构成原关键码的各数位, 能够对最终的散列地址有尽可能接近的影响.  
平方操作可分解为一系列的左移操作以及若干次加法,居中的数位由更多的原数位累积而得.  
截取居中的若干位,可以使得原关键码的各数位对最终地址的影响彼此更为接近

7.折叠汇总  
\(1\)折叠法\(folding\)  
将key分割成_等宽_的若干段,取其_总和_作为地址  
hash\(123456789\)=1368 //123+456+789 自左向右  
hash\(123456789\)=1566 //123+654+789 往复折返  
\(2\)位异或法\(XOR\)  
将key分割成_等宽_的二进制段,经XOR运算得到地址  
hash\(110 011 011\)=110 //110^011^011 自左向右  
hash\(110 011 011\)=011 //110^110^011 往复折返

\*总之,越是随机,越是没有规律,越好

8.伪随机数  
\(1\)计算机中的随机数,实际上都是在前一个所谓随机数基础上,按照确定的计算规则递推而得的. 称为伪随机数发生器  
rand\(x+1\) = \[a \* rand\(x\)\] % M   //M为素数  
\(2\)就逻辑效果而言,等同于将取之方位内的所有整数,按照这种规律重新排为一个貌似随机实则确定的序列; 发生器所返回的是在这个序列中对应于某个特定秩\(x\)的那个元素  
\(3\)最常见的方法,是将这个秩\(x\)取作系统当前的时间

\(4\)伪随机数法  
径取: hash\(key\) = rand\(key\) = \[rand\(0\) \* a^key\] % M  
种子: rand\(0\) = ?  
\(5\)确定+高效+满射+均匀, 是散列和随机数的重要标准

\(6\)伪随机数发生器的实现,因具体平台,不同历史版本而异; 创建的散列表可_移植性_差, 需慎用

9.多项式法\(转换字符串型关键码\)  
\(1\)关键码\(key\)预处理, 转化为整数, 成为散列码 \(hashcode\), 再map到bucket addr.  
\(2\)hash\( s = X0 X1 ... Xn-1 \) = x0 a^\(n-1\) + x1 a^\(n-2\) + x\(n-2\)a^1 + x\(n-1\) //a为某一常数  
\(3\)O\(n\)复杂度  
\(4\)近似多项式

```
static size_t hashCode( char s[] ){
    int h=0;
    for( size_t n=strlen(s),i=0; i<n; i++ ){
        h = (h<<5 | h>>27);
        h+= (int)s[i];
    }

    return (size_t)h;
}//适用于英文字符串
```

1. \(1\)如果每个字符由一个数字代替,计算总和得hashcode,会导致频繁的冲突  
   Tom Marvolo Riddle  
   I am Lord Voldemort

### 散列:排解冲突

1.多槽位法\(multiple slots\)  
\(1\)桶单元细分成若干槽位\(slot\), 存放\(与同一单元\)冲突的词条  
\(一山不容二虎,若真有二虎,用铁丝网隔开\)  
\(2\)查找过程需要多出一步,还需要遍历桶中所有槽位  
\(3\)缺陷:槽位数无法预测,分的过细浪费,而且有可能发生大规模冲突

2.泾渭分明\(独立链,使用closed addressing\)  
\(1\)改用链表\(list\) : linked-list chaining / separate chaining  
\(2\)每个桶存放一个指针, 冲突的词条,组织成链表  
\(3\)优点:无需为每个桶预备多个槽位,任意多次的冲突都可解决,删除操作实现简单,统一  
\(4\)缺点:指针需要额外空间,节点需要动态申请,时间成本高出10^2  
\(5\)最大缺陷:空间未必连续分布,系统缓存几乎失效  
\(系统很难预测访问方向,无法加速查找,当hash表规模非常大,以至于不得不借助IO,这一矛盾就更加突出\)

3.开放地址\(Open addressing\)  
\(1\)使用Closed addressing,事先注定了某个词条对应某个桶  
\(2\)反其道而行,采用开放定址策略\(Open addressing\)  
\(3\)特点:散列表所占用的空间在物理上始终是地址连续的一块,所有的冲突都在这块连续的空间中排解,无需额外空间.  
\(4\)也称为闭散列\(Closed hashing\)

\(5\)Open addressing ~ closed hashing  
\(6\)为每个桶都_事先约定_若干_备用桶_, 构成一个查找链\(probing sequence/chain\)  
\(7\)在特定的情况下,每一个词条都有可能存放在任何一个桶中,但是对每一个特定词条,每个桶都有不同优先级.  
\(8\)优先级最高的是它本来就应该归属的那个桶  
\(9\)从最优桶开始,所有的桶都按照某种优先级关系排成一个序列,查找对应词条的时候顺次尝试每一个桶单元  
\(10\)每个词条所对应的序列,称作试探序列/查找链\(probing sequence/chain\)  
\(11\)沿着查找链逐个查找,命中,成功;或者抵达空桶\(已遍历所有冲突的词条\),失败

4.线性试探\(Linear probing\)  
\(1\)一旦冲突,则试探后一紧邻桶单元,直到命中成功,或抵达空桶失败  
\[hash\(key\)+1\] % M  
\[hash\(key\)+2\] % M  
\[hash\(key\)+3\] % M  
...  
优点  
\(2\)除了数据词条,无需任何附加空间\(指针,链表,或溢出区等\)  
\(3\)查找链具有_局部性_,可充分利用系统缓存,有效减少I/O  
缺点  
\(4\)操作时间 &gt; O\(1\)  
\(5\)冲突增多:以往的冲突,会导致后续的冲突\(clustering\)

5.懒惰删除\(Lazy removal\)  
\(1\)按照开放定址策略:先后插入,相互冲突的一组词条,将存放于同一查找链中  
\(2\)若要删除其中某一词条,应如何实现?  
\(3\)直接删除:清除词条,回收空桶? 问题:查找链切断,后续词条丢失,存在却访问不到  
\(4\)懒惰删除:仅做删除标记,查找链不必续接;

\(5\)查找到删除位置时,不中断继续查找  
\(6\)插入时直接插入删除位置

6.平方试探\(Quadratic probing\)  
\(1\)前面两种方法,封闭定址和开放定址,后者的物理结构更为紧凑,在性能上略具优势\(尤其是大规模的数据\)  
\(2\)然而,以上方法典型的线性试探策略,往往存在大量本不该发生的冲突.这一节改进.  
\(3\)线性试探,位置间距太近,集中于相对小的局部

\(4\)平方试探:以平方数为距离,确定下一试探桶单元  
\[ hash\(key\) + 1^2 \] % M  
\[ hash\(key\) + 2^2 \] % M  
\[ hash\(key\) + 3^2 \] % M  
\[ hash\(key\) + 4^2 \] % M  
...  
\(5\)相对于M取模后,可以保证所有的试探位置都在封闭的散列空间中

7.一利一弊  
\(1\)利:数据聚集现象缓解  
\(2\)弊:若涉及外存,I/O将激增

\(3\)附加问题:散列表中明明存在空桶,按这种策略却永远不能发现  
\(4\)附加问题证明:M是非素数,n^2%M可能的取值必然&lt;ceil\(M/2\)种,只要对应的桶都非空,永远发现不了别的空桶  
\(5\)附加问题证明:M是素数,n^2%M可能的取值恰好=ceil\(M/2\)种,此时恰由查找链的前ceil\(M/2\)项取遍\(恰恰超过50%\)  
\(6\)只要表长是素数,而且能够保证装填因子不超过50%,就一定不会发生以上的负面情况  
\(7\)装填因子是啥来着:实际使用桶数/散列表长度\(总桶数\)

8.至多半载  
否则可能有空桶却无法找到并且利用  
定理: 若M是素数,且装填因子&lt;=0.5,就一定能找出,否则不一定

9.M + LAMBDA  
证明以上结论\(暂略\)

10.双蜓点水\(双向平方试探\)  
交替向前向后以递增的平方数为间隔试探  
\(没看完\)

11.4K + 3  
\(没看\)

12.双平方定理  
\(没看\)

13.泾渭分明  
\(没看\)

