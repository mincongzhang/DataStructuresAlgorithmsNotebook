## 复杂度计算 - 大O记号

对一个算法, 我们不太关心局部或者暂时的一些特性, 我们更倾向于关心它的长远趋势. 我们考虑的问题是随着计算问题规模的不断增长, 它相应的计算成本会如何增长?

所以当问题的规模足够大时, 我们需要考虑计算成本的总体增长趋势, 所以我们会使用渐近分析方法\(Asymptotic analysis\). 并且我们会采用大O记号\(big-O notation\)

![](/assets/big_O.png)

### 常数复杂度\(constant function\) - O\(1\)

这类算法的效率最高

算法特点:

不含转向\(循环, 调用, 递归等\), 顺序执行

### 对数复杂度 - O\(logn\)

常底数无所谓

loga\(n\) = loga\(b\)\*logb\(n\) = O\(logn\)

常数次幂无所谓

log\(n^s\) = clog\(n\) = O\(logn\)

ploy-log function

log^321\(n\)+log^123\(n^2-n+1\) = O\(log^321\(n\)\)

这类算法非常有效, 复杂度无限接近于常数



在常见算法里一般是log2\(n\)

在最简单又最常用的二分法里, 假如对n个数进行二分, 设总运算次数是s, 那么2^s = n

s=log2\(n\)

总共算了s次, 忽略别的细节, 那么可以说类似这样的二分法的复杂度是O\(logn\)

### 多项式复杂度\(polynomial function\) - O\(n^c\)

### 线性复杂度\(linear function\) - O\(n\)

### 从O\(n\)到O\(n^2\)

凡是多项式问题, 我们都归类为可解问题

### 难解问题

指数复杂度\(exponential function\) - O\(2^n\)

从O\(n^c\)到O\(2^n\), 是从有效算法到无效算法的分水岭

### 例子:

子集划分: 逐一枚举S的每一个子集, 并统计其中元素的总和

复杂度O\(2^n\), 这是一个NP完备\(NP-complete\)

就目前计算而言**不存在**可在多项式时间内回答此问题的算法

